{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:15:56] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdmolops\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "- Create variables for data folders\n",
    "- Load data from excel\n",
    "- Load data from non PBT excel and concatenate with PBT/vPvB column\n",
    "- Create 3 datasets for PBT/CMR/PBT+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data variables\n",
    "data_folder = 'raw_data/'\n",
    "data_source = '1 Supplemental Excel data.xlsx'\n",
    "data_source_non = \"Non-PBT.xlsx\"\n",
    "\n",
    "#robustnes and smile variables\n",
    "robcmr = 'Excluded in robustness check 2 - CMR'\n",
    "robpbt = 'Excluded in robustness check 2 - PBT/vPvB'\n",
    "fp_cols = ['SMILES']\n",
    "\n",
    "#cuda check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Load all data from excel supplementary information\n",
    "chems_data  = pd.read_excel(data_folder+data_source, sheet_name = 1, header=1)\n",
    "\n",
    "#Load PBT+ data\n",
    "non_pbt = pd.read_excel(data_folder+data_source_non)\n",
    "non_pbt = non_pbt['SMILES']\n",
    "non_pbt = pd.concat([non_pbt, pd.DataFrame(np.zeros(non_pbt.size), columns=[\"PBT/vPvB\"])], axis=1)\n",
    "\n",
    "\n",
    "# CMR dataset\n",
    "chems_ext = chems_data[fp_cols+['CMR']].loc[chems_data[robcmr] == 0]\n",
    "# PBT dataset\n",
    "chems_maccs = chems_data[fp_cols+['PBT/vPvB']].loc[chems_data[robpbt] == 0]\n",
    "# PBT+ dataset\n",
    "chems_maccs_non = pd.concat([chems_maccs, non_pbt], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all SMARTS for parsing\n",
    "- SMARTS from fingerprint and literature for 4 different characteristics\n",
    "- SMARTS from CYPs from literature, loaded from excle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMARTS for characteristics\n",
    "Hphobe = \"[C&!$(C=[O,N,P,S])&!$(C#N),c,s,S&H0&v2,F,Cl,Br,I]\"\n",
    "\n",
    "Acceptor = \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),\\\n",
    "$([O,S;H0;v2]),\\\n",
    "$([O,S;-]),\\\n",
    "$([N;v3;!$(N-*=[O,N,P,S])]),\\\n",
    "n&H0&+0,\\\n",
    "$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\"\n",
    "\n",
    "Donor=\"[$([N;!H0;v3,v4&+1]),\\\n",
    "$([O,S;H1;+0]),\\\n",
    "n&H1&+0]\"\n",
    "\n",
    "Aromatic =   \"[a]\"\n",
    "\n",
    "#Feature list for parsing in functions\n",
    "feature_list = [Acceptor, Donor, Aromatic, Hphobe]\n",
    "label_list   = ['HB acceptor', 'HB donor', 'Aromatic', 'Hydrophobic']\n",
    "\n",
    "#SOMs SMARTS from file\n",
    "cyp_metabol_feats = pd.read_excel(data_folder + \"output.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for all other functions\n",
    "\n",
    "Creates 2 lists, one with all representations and with the dictionaries containings the mappings\n",
    "- Rep 1 = Conventional\n",
    "- Rep 2 = Hydro aromatic representation\n",
    "- Rep 3 = Bonds representation\n",
    "- Rep 4 = SOM representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(SmilesData, Feats, Bonds, ToxLab):\n",
    "    Rep1 = create_representation1(SmilesData, Feats, Bonds, ToxLab)\n",
    "    Rep1, Rep1Dict = prepare_onehotencoded(Rep1)\n",
    "    Rep1 = transform_DGL(Rep1)\n",
    "\n",
    "    Rep2 = create_representation2(SmilesData, Feats, Bonds, ToxLab)\n",
    "    Rep2, Rep2Dict = prepare_onehotencoded(Rep2)\n",
    "    Rep2 = transform_DGL(Rep2)\n",
    "\n",
    "    Rep3 = create_representation3(SmilesData, Feats, Bonds, ToxLab)\n",
    "    Rep3, Rep3Dict = prepare_onehotencoded(Rep3)\n",
    "    Rep3 = transform_DGL(Rep3)\n",
    "\n",
    "    Rep4 = create_representation4(SmilesData, Feats, Bonds, ToxLab)\n",
    "    Rep4, Rep4Dict = prepare_onehotencoded(Rep4)\n",
    "    Rep4 = transform_DGL(Rep4)\n",
    "    \n",
    "    return [Rep1, Rep2, Rep3, Rep4], [Rep1Dict, Rep2Dict, Rep3Dict, Rep4Dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the conventional representation\n",
    "\n",
    "- Parse the molecules, load the molecule from the smiles and get the information required.\n",
    "- Parse the atomic numbers of the atoms, parse the bond types, both for the labels.\n",
    "- Convert into required data formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation1(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES\n",
    "        mcule = (Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx]))\n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "        \n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph[atom1][atom2]['weight'] = dictionary_bonds.get(bond_str)\n",
    "\n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the Hydro/Aromatic representation\n",
    "\n",
    "- Parse the molecules, load the molecule from the smiles and get the information required.\n",
    "- Parse the atomic numbers of the atoms, parse the bond types, both for the labels.\n",
    "- Parse the SMARTS from the features and add as nodes with the labels.\n",
    "- Convert into required data formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation2(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES and feature locations list\n",
    "        mcule = Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx])\n",
    "        feat1 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[0]))\n",
    "        feat2 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[1]))\n",
    "        feat3 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[2]))\n",
    "        feat4 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[3]))\n",
    "        \n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "        \n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph[atom1][atom2]['weight'] = dictionary_bonds.get(bond_str)\n",
    "\n",
    "        #get start of idx for new nodes\n",
    "        node_count = len(mcule_graph.nodes)\n",
    "        \n",
    "        #add all new features as nodes\n",
    "        for idx, feat_list in enumerate([feat1,feat2,feat3,feat4]):\n",
    "#         for idx, feat_list in enumerate([feat1,feat2]):\n",
    "            for feat in feat_list:\n",
    "                mcule_graph.add_node(node_count)\n",
    "                mcule_graph.add_edge(feat[0], node_count, weight=(len(dictionary_bonds)+1+idx))\n",
    "                #add the new nodes as numbers above the current periodic table\n",
    "                atom_labels.append(120+idx)\n",
    "                node_count+=1\n",
    "        \n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the Bonds representation\n",
    "\n",
    "- Parse the molecules, load the molecule from the smiles and get the information required.\n",
    "- Parse the atomic numbers of the atoms, parse the bond types, both for the labels.\n",
    "- Parse the bonds and add as nodes with the labels.\n",
    "- Convert into required data formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation3(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES\n",
    "        mcule = Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx])\n",
    "        \n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "\n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #get start of idx for new nodes\n",
    "        node_count = len(mcule_graph.nodes)\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph.remove_edge(atom1,atom2)\n",
    "            mcule_graph.add_node(node_count)\n",
    "            mcule_graph.add_edge(atom1, node_count, weight=dictionary_bonds.get(bond_str))\n",
    "            mcule_graph.add_edge(atom2, node_count, weight=dictionary_bonds.get(bond_str))\n",
    "            atom_labels.append(120+dictionary_bonds.get(bond_str))\n",
    "            node_count += 1\n",
    "\n",
    "\n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the SOMs representation\n",
    "\n",
    "- Parse the molecules, load the molecule from the smiles and get the information required.\n",
    "- Parse the atomic numbers of the atoms, parse the bond types, both for the labels.\n",
    "- Parse the SMARTS from the CYPs and add as nodes with the labels.\n",
    "- Convert into required data formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation4(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES\n",
    "        mcule = (Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx]))\n",
    "        \n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "        \n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph[atom1][atom2]['weight'] = dictionary_bonds.get(bond_str)\n",
    "        \n",
    "        #Create matrix with multi hot encoded array for every atom and metabolism features\n",
    "        feat_cyp = np.zeros((len(list(mcule.GetAtoms())), 71))\n",
    "        for idx in range(cyp_metabol_feats.shape[0]):\n",
    "            cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(cyp_metabol_feats['SMARTS'].iloc[idx]))\n",
    "            for feat in cyp_idx_feats:\n",
    "                feat_cyp[feat[0]][idx] = 1\n",
    "        \n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab, feat_cyp])\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox', 'cyps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to prepare labels to one hot labels\n",
    "\n",
    "- Parse label list to range higher than possible\n",
    "- Parse label list to 0 to n mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_onehotencoded(rep_dataset):\n",
    "    atom_list = [x for x in rep_dataset['atoms'].values]\n",
    "    atom_flat = [item for sublist in atom_list for item in sublist]\n",
    "    atom_set  = sorted(list(set(atom_flat)))\n",
    "    \n",
    "    #first replace with numbers above max of atom set to avoid multiple wrong replacing\n",
    "    replace1  = list(range(max(atom_set)+1, len(atom_set)+max(atom_set)+1))\n",
    "    for i, a_list in enumerate(atom_list):\n",
    "        for j, atom_l in enumerate(a_list):\n",
    "            for idx, atom_s in enumerate(atom_set):\n",
    "                if atom_l == atom_s:\n",
    "                    atom_list[i][j] = replace1[idx]\n",
    "                    \n",
    "    #second replace with numbers in range zero to length atom set \n",
    "    replace2  = list(range(len(replace1)))\n",
    "    for i, a_list in enumerate(atom_list):\n",
    "        for j, atom_l in enumerate(a_list):\n",
    "            for idx, atom_s in enumerate(replace1):\n",
    "                if atom_l == atom_s:\n",
    "                    atom_list[i][j] = replace2[idx]\n",
    "    \n",
    "    rep_dataset['atoms'] = atom_list\n",
    "    dict_onehot = {}\n",
    "    for i, d in enumerate(replace2):\n",
    "        dict_onehot[d] = atom_set[i]\n",
    "\n",
    "    return rep_dataset, dict_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to required data formatting\n",
    "- Create list with atom type feature vectors\n",
    "- Bond type adjacency matrix with labels as indices\n",
    "- Label for the tox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_DGL(dataframe):\n",
    "    DGL_list = []\n",
    "    #convert to correct conventions\n",
    "    max_atoms = max([max(atoms) for atoms in dataframe['atoms']])\n",
    "    dataframe['matrix'] = dataframe['matrix'].apply(lambda x: torch.tensor(x))\n",
    "    dataframe['atoms']  = dataframe['atoms'].apply(lambda x: torch.tensor(x))\n",
    "    #create list of graph info dictionaries\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        mol_dict = {}\n",
    "        mol_dict['num_atom']  = int(len(dataframe['atoms'].iloc[i]))\n",
    "        if 'cyps' in dataframe.columns:\n",
    "            onehot_atoms = np.eye(max_atoms+1)[dataframe['atoms'].iloc[i]]\n",
    "            onehot_cyps = dataframe['cyps'].iloc[i]\n",
    "            mol_dict['atom_type'] = np.concatenate((onehot_atoms,onehot_cyps), axis=1)\n",
    "        else:\n",
    "            mol_dict['atom_type'] = np.eye(max_atoms+1)[dataframe['atoms'].iloc[i]]\n",
    "        mol_dict['bond_type'] = dataframe['matrix'].iloc[i]\n",
    "        mol_dict['label']     = dataframe['tox'].iloc[i]\n",
    "        DGL_list.append(mol_dict)\n",
    "    return DGL_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save the representations to the data folder\n",
    "Save the dictionary mappings and the data for every representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reps(reps, dicts, save_name):\n",
    "    for idx, rep in enumerate(reps):\n",
    "        pickle.dump(rep, open(save_name + str(idx+1) + \".pickle\",\"wb\"))\n",
    "        pickle.dump(dicts[idx], open(save_name + str(idx+1) + \"_dict.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove not parseable molecules\n",
    "# these molecules could not be parse with RDKIT and gave an error\n",
    "if chems_maccs_non.shape[0] == 975:\n",
    "    chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[506])\n",
    "    chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[751])\n",
    "    chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[794])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse representations and save them\n",
    "Call the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_dict = {'SINGLE':1, 'DOUBLE':2, 'TRIPLE':3, 'AROMATIC':4}\n",
    "\n",
    "CMR_reps, CMR_dicts = create_dataset(chems_ext, feature_list, bond_dict, 'CMR')\n",
    "PBT_reps, PBT_dicts = create_dataset(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBTn_reps, PBTn_dicts = create_dataset(chems_maccs_non, feature_list, bond_dict, 'PBT/vPvB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_reps(CMR_reps, CMR_dicts, \"data/CMR_Rep\")\n",
    "save_reps(PBT_reps, PBT_dicts, \"data/PBT_Rep\")\n",
    "save_reps(PBTn_reps, PBTn_dicts, \"data/PBTn_Rep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
