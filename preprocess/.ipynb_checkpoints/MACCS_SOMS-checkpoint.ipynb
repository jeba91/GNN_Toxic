{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdmolops\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'raw_data/'\n",
    "data_source = '1 Supplemental Excel data.xlsx'\n",
    "data_source_non = \"Non-PBT.xlsx\"\n",
    "robcmr = 'Excluded in robustness check 2 - CMR'\n",
    "robpbt = 'Excluded in robustness check 2 - PBT/vPvB'\n",
    "sm = 'SMILES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "chems_data  = pd.read_excel(data_folder+data_source, sheet_name = 1, header=1)\n",
    "non_pbt = pd.read_excel(data_folder+data_source_non)\n",
    "non_pbt = non_pbt['SMILES']\n",
    "non_pbt = pd.concat([non_pbt, pd.DataFrame(np.zeros([481]), columns=[\"PBT/vPvB\"])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_cols = ['SMILES']\n",
    "\n",
    "chems_ext = chems_data[fp_cols+['CMR']].loc[chems_data[robcmr] == 0]\n",
    "\n",
    "chems_maccs = chems_data[fp_cols+['PBT/vPvB']].loc[chems_data[robpbt] == 0]\n",
    "\n",
    "chems_maccs_non = pd.concat([chems_maccs, non_pbt], axis=0)\n",
    "\n",
    "# chems_data['CM'] = np.where((chems_data['C'] == 1) | (chems_data['M'] == 1), 1, 0)\n",
    "\n",
    "chems_cm = chems_data[fp_cols+['CM']].loc[chems_data[robcmr] == 0]\n",
    "chems_r = chems_data[fp_cols+['R']].loc[chems_data[robcmr] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(chems_cm.shape)\n",
    "# print(chems_r.shape)\n",
    "print(chems_ext.shape)\n",
    "print(chems_maccs.shape)\n",
    "print(chems_maccs_non.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chems_cm.loc[chems_cm['CM']==1].shape)\n",
    "print(chems_cm.loc[chems_cm['CM']==0].shape)\n",
    "print(chems_r.loc[chems_r['CMR']==1].shape)\n",
    "print(chems_r.loc[chems_r['CMR']==0].shape)\n",
    "print(chems_ext.loc[chems_ext['CMR']==1].shape)\n",
    "print(chems_ext.loc[chems_ext['CMR']==0].shape)\n",
    "print(chems_maccs.loc[chems_maccs['PBT/vPvB']==1].shape)\n",
    "print(chems_maccs.loc[chems_maccs['PBT/vPvB']==0].shape)\n",
    "print(chems_maccs_non.loc[chems_maccs_non['PBT/vPvB']==1].shape)\n",
    "print(chems_maccs_non.loc[chems_maccs_non['PBT/vPvB']==0].shape)\n",
    "# print(chems_fcfp.loc[chems_fcfp['ED']==1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carbon_NonPolar = \"[C&!$(C=[O,N,P,S])&!$(C#N)]\"\n",
    "Hphobe = \"[C&!$(C=[O,N,P,S])&!$(C#N),c,s,S&H0&v2,F,Cl,Br,I]\"\n",
    "\n",
    "Acceptor = \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),\\\n",
    "$([O,S;H0;v2]),\\\n",
    "$([O,S;-]),\\\n",
    "$([N;v3;!$(N-*=[O,N,P,S])]),\\\n",
    "n&H0&+0,\\\n",
    "$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\"\n",
    "\n",
    "Donor=\"[$([N;!H0;v3,v4&+1]),\\\n",
    "$([O,S;H1;+0]),\\\n",
    "n&H1&+0]\"\n",
    "\n",
    "Aromatic =   \"[a]\"\n",
    "\n",
    "feature_list = [Acceptor, Donor, Aromatic, Hphobe]\n",
    "# feature_list = [Acceptor, Donor]\n",
    "\n",
    "label_list   = ['HB acceptor', 'HB donor', 'Aromatic', 'Hydrophobic']\n",
    "# tox_list_pbt = ['non-PBT/vPvB','PBT/vPvB']\n",
    "# tox_list_cmr = ['non-CMR','CMR']\n",
    "\n",
    "cyp_metabol_feats = pd.read_excel(\"output.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonds=[]\n",
    "# for mol_idx in range(chems_maccs.shape[0]):\n",
    "#     mole = Chem.MolFromSmiles(chems_maccs['SMILES'].iloc[mol_idx])\n",
    "#     A = Chem.GetAdjacencyMatrix(mole)\n",
    "#     edge_list = (A != 0).nonzero()\n",
    "#     for a,b in np.transpose(edge_list):\n",
    "#         bonds.append(str(mole.GetBondBetweenAtoms(int(a),int(b)).GetBondType()))\n",
    "# print(list(set(bonds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MACCSkeys\n",
    "print(MACCSkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"MACCS_SMARTS.txt\",\"r\")\n",
    "maccs = []\n",
    "for idx, line in enumerate(file1.readlines()):\n",
    "    maccs.append([idx, line.split(\":('\")[1].rsplit(\"',\",1)[0]])\n",
    "maccs = pd.DataFrame(maccs, columns=[\"idx\",\"SMARTS\"])\n",
    "print(maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maccs_som(dataset, maccs_smarts, soms_smarts):\n",
    "    ml_data = []\n",
    "    for mol_idx in range(dataset.shape[0]):\n",
    "        mol_feats = np.zeros([len(maccs_smarts)+len(soms_smarts),1])\n",
    "        mcule = Chem.MolFromSmiles(dataset['SMILES'].iloc[mol_idx])\n",
    "\n",
    "        for i in range(166):\n",
    "            if maccs['SMARTS'].iloc[i] != '?':\n",
    "                cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(maccs['SMARTS'].iloc[i]))\n",
    "                for csub in cyp_idx_feats:\n",
    "                    for c in csub:\n",
    "                        mol_feats[i] += 1\n",
    "                        \n",
    "        for i in range(71):\n",
    "            cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(cyp_metabol_feats['SMARTS'].iloc[i]))\n",
    "            for c in cyp_idx_feats:\n",
    "                mol_feats[i+166] += 1\n",
    "        ml_data.append([dataset['SMILES'].iloc[mol_idx], dataset['PBT/vPvB'].iloc[mol_idx], mol_feats[feats_idx].ravel()])\n",
    "    return ml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robustness check good\n",
    "chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[506])\n",
    "chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[751])\n",
    "chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[794])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = maccs_som(chems_maccs_non, maccs, cyp_metabol_feats)\n",
    "dat = pd.DataFrame(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(dat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = dat[2].values\n",
    "y = dat[1].values\n",
    "X = [[int(number) for number in group] for group in X]\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200,500,1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8,12,15],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 5)\n",
    "CV_rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [1, 10, 100, 1000, 2000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=i, shuffle=True)\n",
    "    X = dat[2].values\n",
    "    y = dat[1].values\n",
    "    X = [[int(number) for number in group] for group in X]\n",
    "    skf.get_n_splits(X, y)\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    X = np.array(X)\n",
    "    bac=[]\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = SVC(C=1000, kernel='rbf', gamma=1e-4)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        bac.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    print(np.mean(bac), np.std(bac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=i, shuffle=True)\n",
    "    X = dat[2].values\n",
    "    y = dat[1].values\n",
    "    X = [[int(number) for number in group] for group in X]\n",
    "    skf.get_n_splits(X, y)\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    X = np.array(X)\n",
    "    bac=[]\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = RandomForestClassifier(criterion='gini', max_depth=15, max_features='auto', n_estimators=500)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        bac.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    print(np.mean(bac), np.std(bac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_idx = feature_importances.index[-50:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_importances = pd.DataFrame(clf.feature_importances_,columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "feature_importances.plot.barh(figsize=(15,50))\n",
    "print(feature_importances.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maccs['SMARTS'].iloc[86])\n",
    "print(maccs['SMARTS'].iloc[133])\n",
    "print(maccs['SMARTS'].iloc[158])\n",
    "print(maccs['SMARTS'].iloc[106])\n",
    "print()\n",
    "print(\"SOM\", cyp_metabol_feats['SMARTS'].iloc[191-166])\n",
    "print()\n",
    "print(maccs['SMARTS'].iloc[41])\n",
    "print(maccs['SMARTS'].iloc[40])\n",
    "print(maccs['SMARTS'].iloc[49])\n",
    "print(maccs['SMARTS'].iloc[160])\n",
    "print(maccs['SMARTS'].iloc[140])\n",
    "print(maccs['SMARTS'].iloc[145])\n",
    "print(maccs['SMARTS'].iloc[100])\n",
    "print(maccs['SMARTS'].iloc[163])\n",
    "print(maccs['SMARTS'].iloc[157])\n",
    "print(maccs['SMARTS'].iloc[135])\n",
    "print(maccs['SMARTS'].iloc[159])\n",
    "print(maccs['SMARTS'].iloc[153])\n",
    "print()\n",
    "print(\"SOM\", cyp_metabol_feats['SMARTS'].iloc[191-166])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "X = np.array(X)\n",
    "bac=[]\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = SVC(C=1000, kernel='rbf', gamma=1e-4)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    bac.append(balanced_accuracy_score(y_test,y_pred))\n",
    "print(np.mean(bac), np.std(bac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tellen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chems_maccs.loc[chems_maccs['PBT/vPvB']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol_feats = np.zeros([320,1])\n",
    "# print(mol_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tellen2 = np.zeros([71,1])\n",
    "# for i in range(chems_maccs.loc[chems_maccs['PBT/vPvB']==0].shape[0]):\n",
    "#     mcule = Chem.MolFromSmiles(chems_maccs.loc[chems_maccs['PBT/vPvB']==0]['SMILES'].iloc[i])\n",
    "\n",
    "#     feat_cyp = np.zeros((len(list(mcule.GetAtoms())), 71))\n",
    "#     for i in range(71):\n",
    "#         cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(cyp_metabol_feats['SMARTS'].iloc[i]))\n",
    "#         for c in cyp_idx_feats:\n",
    "#             tellen2[c] +=1\n",
    "# tellen2 = 100*(tellen2/381)\n",
    "# tellen2 = np.zeros([166,1])\n",
    "# for mol_idx in range(chems_maccs.loc[chems_maccs['PBT/vPvB']==0].shape[0]):\n",
    "#     mcule = Chem.MolFromSmiles(chems_maccs.loc[chems_maccs['PBT/vPvB']==0]['SMILES'].iloc[mol_idx])\n",
    "\n",
    "#     for i in range(166):\n",
    "#         if maccs['SMARTS'].iloc[i] != '?':\n",
    "#             cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(maccs['SMARTS'].iloc[i]))\n",
    "#             for csub in cyp_idx_feats:\n",
    "#                 for c in csub:\n",
    "#                     tellen2[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tellen = pd.DataFrame(np.concatenate((tellen1,tellen2), axis=1))\n",
    "\n",
    "# tellen.plot.barh(figsize=(15,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation1(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES\n",
    "        mcule = (Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx]))\n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "        \n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph[atom1][atom2]['weight'] = dictionary_bonds.get(bond_str)\n",
    "\n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation2(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES and feature locations list\n",
    "        mcule = Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx])\n",
    "        feat1 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[0]))\n",
    "        feat2 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[1]))\n",
    "        feat3 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[2]))\n",
    "        feat4 = mcule.GetSubstructMatches(Chem.MolFromSmarts(features[3]))\n",
    "        \n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "        \n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph[atom1][atom2]['weight'] = dictionary_bonds.get(bond_str)\n",
    "\n",
    "        #get start of idx for new nodes\n",
    "        node_count = len(mcule_graph.nodes)\n",
    "        \n",
    "        #add all new features as nodes\n",
    "        for idx, feat_list in enumerate([feat1,feat2,feat3,feat4]):\n",
    "#         for idx, feat_list in enumerate([feat1,feat2]):\n",
    "            for feat in feat_list:\n",
    "                mcule_graph.add_node(node_count)\n",
    "                mcule_graph.add_edge(feat[0], node_count, weight=(len(dictionary_bonds)+1+idx))\n",
    "                #add the new nodes as numbers above the current periodic table\n",
    "                atom_labels.append(120+idx)\n",
    "                node_count+=1\n",
    "        \n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation3(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES\n",
    "        mcule = Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx])\n",
    "        \n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "\n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #get start of idx for new nodes\n",
    "        node_count = len(mcule_graph.nodes)\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph.remove_edge(atom1,atom2)\n",
    "            mcule_graph.add_node(node_count)\n",
    "            mcule_graph.add_edge(atom1, node_count, weight=dictionary_bonds.get(bond_str))\n",
    "            mcule_graph.add_edge(atom2, node_count, weight=dictionary_bonds.get(bond_str))\n",
    "            atom_labels.append(120+dictionary_bonds.get(bond_str))\n",
    "            node_count += 1\n",
    "\n",
    "\n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab])\n",
    "\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_representation4(smiles_data, features, dictionary_bonds, tox_label):\n",
    "    matrices_dataset = []\n",
    "    \n",
    "    for mol_idx in range(smiles_data.shape[0]):\n",
    "        #get molecule from SMILES\n",
    "        mcule = (Chem.MolFromSmiles(smiles_data['SMILES'].iloc[mol_idx]))\n",
    "        \n",
    "        #adjacency matrix, molecule in graph and edge list\n",
    "        adj_matrix = Chem.GetAdjacencyMatrix(mcule)\n",
    "        mcule_graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        edge_list = (np.tril(adj_matrix) != 0).nonzero()\n",
    "        \n",
    "        #get label for each atom as list\n",
    "        atom_labels = []\n",
    "        for _, atom in enumerate(mcule.GetAtoms()):\n",
    "            atom_labels.append(atom.GetAtomicNum())\n",
    "        \n",
    "        #add edge label as weight to the graph representation, use dict of bonds\n",
    "        for atom1,atom2 in np.transpose(edge_list):\n",
    "            bond_str = str(mcule.GetBondBetweenAtoms(int(atom1),int(atom2)).GetBondType())\n",
    "            mcule_graph[atom1][atom2]['weight'] = dictionary_bonds.get(bond_str)\n",
    "        \n",
    "        #Create matrix with one hot encoded array for every atom and metabolism features\n",
    "        feat_cyp = np.zeros((len(list(mcule.GetAtoms())), 71))\n",
    "        for idx in range(cyp_metabol_feats.shape[0]):\n",
    "            cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(cyp_metabol_feats['SMARTS'].iloc[idx]))\n",
    "            for feat in cyp_idx_feats:\n",
    "                feat_cyp[feat[0]][idx] = 1\n",
    "        \n",
    "        #add adjancency matrix with edge labels, atom labels and label to dataset\n",
    "        adj_mat = nx.to_numpy_matrix(mcule_graph).astype(int)\n",
    "        tox_lab = smiles_data[tox_label].iloc[mol_idx]\n",
    "        matrices_dataset.append([adj_mat, atom_labels, tox_lab, feat_cyp])\n",
    "\n",
    "    return pd.DataFrame(matrices_dataset, columns=['matrix', 'atoms', 'tox', 'cyps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_onehotencoded(rep_dataset):\n",
    "    atom_list = [x for x in rep_dataset['atoms'].values]\n",
    "    atom_flat = [item for sublist in atom_list for item in sublist]\n",
    "    atom_set  = sorted(list(set(atom_flat)))\n",
    "    \n",
    "    #first replace with numbers above max of atom set to avoid multiple wrong replacing\n",
    "    replace1  = list(range(max(atom_set)+1, len(atom_set)+max(atom_set)+1))\n",
    "    for i, a_list in enumerate(atom_list):\n",
    "        for j, atom_l in enumerate(a_list):\n",
    "            for idx, atom_s in enumerate(atom_set):\n",
    "                if atom_l == atom_s:\n",
    "                    atom_list[i][j] = replace1[idx]\n",
    "                    \n",
    "    #second replace with numbers in range zero to length atom set \n",
    "    replace2  = list(range(len(replace1)))\n",
    "    for i, a_list in enumerate(atom_list):\n",
    "        for j, atom_l in enumerate(a_list):\n",
    "            for idx, atom_s in enumerate(replace1):\n",
    "                if atom_l == atom_s:\n",
    "                    atom_list[i][j] = replace2[idx]\n",
    "    \n",
    "    rep_dataset['atoms'] = atom_list\n",
    "    dict_onehot = {}\n",
    "    for i, d in enumerate(replace2):\n",
    "        dict_onehot[d] = atom_set[i]\n",
    "\n",
    "    return rep_dataset, dict_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_DGL(dataframe):\n",
    "    DGL_list = []\n",
    "    #convert to correct conventions\n",
    "    max_atoms = max([max(atoms) for atoms in dataframe['atoms']])\n",
    "    dataframe['matrix'] = dataframe['matrix'].apply(lambda x: torch.tensor(x))\n",
    "    dataframe['atoms']  = dataframe['atoms'].apply(lambda x: torch.tensor(x))\n",
    "    #create list of graph info dictionaries\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        mol_dict = {}\n",
    "        mol_dict['num_atom']  = int(len(dataframe['atoms'].iloc[i]))\n",
    "        if 'cyps' in dataframe.columns:\n",
    "            onehot_atoms = np.eye(max_atoms+1)[dataframe['atoms'].iloc[i]]\n",
    "            onehot_cyps = dataframe['cyps'].iloc[i]\n",
    "            mol_dict['atom_type'] = np.concatenate((onehot_atoms,onehot_cyps), axis=1)\n",
    "        else:\n",
    "            mol_dict['atom_type'] = np.eye(max_atoms+1)[dataframe['atoms'].iloc[i]]\n",
    "        mol_dict['bond_type'] = dataframe['matrix'].iloc[i]\n",
    "        mol_dict['label']     = dataframe['tox'].iloc[i]\n",
    "        DGL_list.append(mol_dict)\n",
    "    return DGL_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bond_dict = {'SINGLE':1, 'DOUBLE':2, 'TRIPLE':3, 'AROMATIC':4}\n",
    "\n",
    "# MUT_Rep1 = create_representation1(mutag, feature_list, bond_dict, 'PBT/vPvB')\n",
    "# MUT_Rep1, PBT_Rep1_dict = prepare_onehotencoded(PBT_Rep1)\n",
    "# MUT_Rep1 = transform_DGL(PBT_Rep1)\n",
    "\n",
    "# MUT_Rep2 = create_representation2(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "# MUT_Rep2, PBT_Rep2_dict = prepare_onehotencoded(PBT_Rep2)\n",
    "# MUT_Rep2 = transform_DGL(PBT_Rep2)\n",
    "\n",
    "# MUT_Rep3 = create_representation3(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "# MUT_Rep3, PBT_Rep3_dict = prepare_onehotencoded(PBT_Rep3)\n",
    "# MUT_Rep3 = transform_DGL(PBT_Rep3)\n",
    "\n",
    "# MUT_Rep4 = create_representation4(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "# MUT_Rep4, PBT_Rep4_dict = prepare_onehotencoded(PBT_Rep4)\n",
    "# MUT_Rep4 = transform_DGL(PBT_Rep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(tellen1.reshape(1,-1))),tellen1.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(tellen1):\n",
    "    print(tellen1[i],tellen2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_dict = {'SINGLE':1, 'DOUBLE':2, 'TRIPLE':3, 'AROMATIC':4}\n",
    "\n",
    "CM_Rep1 = create_representation1(chems_cm, feature_list, bond_dict, 'CM')\n",
    "CM_Rep1, CM_Rep1_dict = prepare_onehotencoded(CM_Rep1)\n",
    "CM_Rep1 = transform_DGL(CM_Rep1)\n",
    "\n",
    "CM_Rep2 = create_representation2(chems_cm, feature_list, bond_dict, 'CM')\n",
    "CM_Rep2, CM_Rep2_dict = prepare_onehotencoded(CM_Rep2)\n",
    "CM_Rep2 = transform_DGL(CM_Rep2)\n",
    "\n",
    "CM_Rep3 = create_representation3(chems_cm, feature_list, bond_dict, 'CM')\n",
    "CM_Rep3, CM_Rep3_dict = prepare_onehotencoded(CM_Rep3)\n",
    "CM_Rep3 = transform_DGL(CM_Rep3)\n",
    "\n",
    "CM_Rep4 = create_representation4(chems_cm, feature_list, bond_dict, 'CM')\n",
    "CM_Rep4, CM_Rep4_dict = prepare_onehotencoded(CM_Rep4)\n",
    "CM_Rep4 = transform_DGL(CM_Rep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_dict = {'SINGLE':1, 'DOUBLE':2, 'TRIPLE':3, 'AROMATIC':4}\n",
    "\n",
    "R_Rep1 = create_representation1(chems_r, feature_list, bond_dict, 'CMR')\n",
    "R_Rep1, R_Rep1_dict = prepare_onehotencoded(R_Rep1)\n",
    "R_Rep1 = transform_DGL(R_Rep1)\n",
    "\n",
    "R_Rep2 = create_representation2(chems_r, feature_list, bond_dict, 'CMR')\n",
    "R_Rep2, R_Rep2_dict = prepare_onehotencoded(R_Rep2)\n",
    "R_Rep2 = transform_DGL(R_Rep2)\n",
    "\n",
    "R_Rep3 = create_representation3(chems_r, feature_list, bond_dict, 'CMR')\n",
    "R_Rep3, R_Rep3_dict = prepare_onehotencoded(R_Rep3)\n",
    "R_Rep3 = transform_DGL(R_Rep3)\n",
    "\n",
    "R_Rep4 = create_representation4(chems_r, feature_list, bond_dict, 'CMR')\n",
    "R_Rep4, R_Rep4_dict = prepare_onehotencoded(R_Rep4)\n",
    "R_Rep4 = transform_DGL(R_Rep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_dict = {'SINGLE':1, 'DOUBLE':2, 'TRIPLE':3, 'AROMATIC':4}\n",
    "\n",
    "\n",
    "PBT_Rep1 = create_representation1(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep1, PBT_Rep1_dict = prepare_onehotencoded(PBT_Rep1)\n",
    "PBT_Rep1 = transform_DGL(PBT_Rep1)\n",
    "\n",
    "PBT_Rep2 = create_representation2(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep2, PBT_Rep2_dict = prepare_onehotencoded(PBT_Rep2)\n",
    "PBT_Rep2 = transform_DGL(PBT_Rep2)\n",
    "\n",
    "PBT_Rep3 = create_representation3(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep3, PBT_Rep3_dict = prepare_onehotencoded(PBT_Rep3)\n",
    "PBT_Rep3 = transform_DGL(PBT_Rep3)\n",
    "\n",
    "PBT_Rep4 = create_representation4(chems_maccs, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep4, PBT_Rep4_dict = prepare_onehotencoded(PBT_Rep4)\n",
    "PBT_Rep4 = transform_DGL(PBT_Rep4)\n",
    "\n",
    "CMR_Rep1 = create_representation1(chems_ext, feature_list, bond_dict, 'CMR')\n",
    "CMR_Rep1, CMR_Rep1_dict = prepare_onehotencoded(CMR_Rep1)\n",
    "CMR_Rep1 = transform_DGL(CMR_Rep1)\n",
    "\n",
    "CMR_Rep2 = create_representation2(chems_ext, feature_list, bond_dict, 'CMR')\n",
    "CMR_Rep2, CMR_Rep2_dict = prepare_onehotencoded(CMR_Rep2)\n",
    "CMR_Rep2 = transform_DGL(CMR_Rep2)\n",
    "\n",
    "CMR_Rep3 = create_representation3(chems_ext, feature_list, bond_dict, 'CMR')\n",
    "CMR_Rep3, CMR_Rep3_dict = prepare_onehotencoded(CMR_Rep3)\n",
    "CMR_Rep3 = transform_DGL(CMR_Rep3)\n",
    "\n",
    "CMR_Rep4 = create_representation4(chems_ext, feature_list, bond_dict, 'CMR')\n",
    "CMR_Rep4, CMR_Rep4_dict = prepare_onehotencoded(CMR_Rep4)\n",
    "CMR_Rep4 = transform_DGL(CMR_Rep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robustness check good\n",
    "chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[506])\n",
    "chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[751])\n",
    "chems_maccs_non = chems_maccs_non.drop(chems_maccs_non.index[794])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_dict = {'SINGLE':1, 'DOUBLE':2, 'TRIPLE':3, 'AROMATIC':4}\n",
    "\n",
    "PBT_Rep1n = create_representation1(chems_maccs_non, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep1n, PBT_Rep1_dictn = prepare_onehotencoded(PBT_Rep1n)\n",
    "PBT_Rep1n = transform_DGL(PBT_Rep1n)\n",
    "\n",
    "PBT_Rep2n = create_representation2(chems_maccs_non, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep2n, PBT_Rep2_dictn = prepare_onehotencoded(PBT_Rep2n)\n",
    "PBT_Rep2n = transform_DGL(PBT_Rep2n)\n",
    "\n",
    "PBT_Rep3n = create_representation3(chems_maccs_non, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep3n, PBT_Rep3_dictn = prepare_onehotencoded(PBT_Rep3n)\n",
    "PBT_Rep3n = transform_DGL(PBT_Rep3n)\n",
    "\n",
    "PBT_Rep4n = create_representation4(chems_maccs_non, feature_list, bond_dict, 'PBT/vPvB')\n",
    "PBT_Rep4n, PBT_Rep4_dictn = prepare_onehotencoded(PBT_Rep4n)\n",
    "PBT_Rep4n = transform_DGL(PBT_Rep4n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def data_desc(dataset, label):\n",
    "    bond_counter = Counter()\n",
    "    atom_counter = Counter()\n",
    "    max_b = 0\n",
    "    max_a = 0\n",
    "    min_b = 100000\n",
    "    min_a = 100000\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[i]['label'] == label:\n",
    "            bond_counter.update(np.array(dataset[i]['bond_type'])[np.array(dataset[i]['bond_type']).nonzero()])\n",
    "            atom_counter.update(dataset[i]['atom_type'].nonzero()[1])\n",
    "            lenb = len(np.array(dataset[i]['bond_type'])[np.array(dataset[i]['bond_type']).nonzero()])\n",
    "            lena = len(dataset[i]['atom_type'].nonzero()[1])\n",
    "            if lenb > max_b:\n",
    "                max_b = lenb\n",
    "            if lena > max_a:\n",
    "                max_a = lena\n",
    "            if lenb < min_b:\n",
    "                min_b = lenb\n",
    "            if lena < min_a:\n",
    "                min_a = lena\n",
    "#     print('b',(sum(list(bond_counter.values()))/2))\n",
    "#     print('a',sum(list(atom_counter.values())))\n",
    "#     print(\"a\", max_a)\n",
    "#     print(\"a\", min_a)\n",
    "#     print(bond_counter)\n",
    "    print(atom_counter[11])\n",
    "    print(atom_counter[12])\n",
    "    print(atom_counter[13])\n",
    "    print(atom_counter[14])\n",
    "    print(sorted(list(atom_counter.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cyp = np.zeros((len(list(mcule.GetAtoms())), 71))\n",
    "print(feat_cyp[0])\n",
    "for i in range(71):\n",
    "    cyp_idx_feats = mcule.GetSubstructMatches(Chem.MolFromSmarts(cyp_metabol_feats['SMARTS'].iloc[i]))\n",
    "    print(cyp_idx_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def prior_desc(dataset, label, check):\n",
    "    check_list = [0,0,0,0]\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[i]['label'] == label:\n",
    "            bonds = np.array(dataset[i]['bond_type'])[np.array(dataset[i]['bond_type']).nonzero()]\n",
    "            atoms = dataset[i]['atom_type'].nonzero()[1]\n",
    "            if check[0] in atoms:\n",
    "                check_list[0] +=1\n",
    "            if check[1] in atoms:\n",
    "                check_list[1] +=1\n",
    "            if check[2] in atoms:\n",
    "                check_list[2] +=1\n",
    "            if check[3] in atoms:\n",
    "                check_list[3] +=1\n",
    "    return check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PBT_Rep2_dictn)\n",
    "\n",
    "# data_desc(CMR_Rep2, 0)\n",
    "# print(sum(chems_ext['CMR']==0))\n",
    "# print()\n",
    "# data_desc(CMR_Rep2, 1)\n",
    "# print(sum(chems_ext['CMR']==1))\n",
    "# print()\n",
    "\n",
    "a = prior_desc(PBT_Rep2n, 0, [11,12,13,14])\n",
    "for i in a:\n",
    "    print(\"%.2f%%\" % float(100*(i/sum(chems_maccs_non['PBT/vPvB']==0))))\n",
    "print(\"\")\n",
    "a = prior_desc(PBT_Rep2n, 1, [11,12,13,14])\n",
    "for i in a:\n",
    "    print(\"%.2f%%\" % float(100*(i/sum(chems_maccs_non['PBT/vPvB']==1))))\n",
    "\n",
    "# data_desc(PBT_Rep2n, 0)\n",
    "# print(sum(chems_maccs_non['PBT/vPvB']==0))\n",
    "# print()\n",
    "# data_desc(PBT_Rep2n, 1)\n",
    "# [Acceptor, Donor, Aromatic, Hphobe]\n",
    "# print(sum(chems_maccs_non['PBT/vPvB']==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([196, 203, 295, 495, 685, 870, 878])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chems_maccs_non['SMILES'].iloc[[19, 81, 23, 92, 22, 921, 25]]:\n",
    "# for i in chems_maccs_non['SMILES'].iloc[[469, 53, 95, 136, 94, 231, 916, 359, 518]]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chems_ext['SMILES'].iloc[[365,271,210,110,304]]:\n",
    "    print(i)\n",
    "print()\n",
    "for i in chems_ext['SMILES'].iloc[[237,463,466,238,280]]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print(chems_maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(CM_Rep1, open(\"data/CM_Rep1.pickle\",\"wb\"))\n",
    "pickle.dump(CM_Rep1, open(\"data/CM_Rep2.pickle\",\"wb\"))\n",
    "pickle.dump(CM_Rep1, open(\"data/CM_Rep3.pickle\",\"wb\"))\n",
    "pickle.dump(CM_Rep1, open(\"data/CM_Rep4.pickle\",\"wb\"))\n",
    "\n",
    "pickle.dump(CM_Rep1_dict, open(\"data/CM_Rep1_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CM_Rep2_dict, open(\"data/CM_Rep2_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CM_Rep3_dict, open(\"data/CM_Rep3_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CM_Rep4_dict, open(\"data/CM_Rep4_dict.pickle\",\"wb\"))\n",
    "\n",
    "pickle.dump(R_Rep1, open(\"data/R_Rep1.pickle\",\"wb\"))\n",
    "pickle.dump(R_Rep2, open(\"data/R_Rep2.pickle\",\"wb\"))\n",
    "pickle.dump(R_Rep3, open(\"data/R_Rep3.pickle\",\"wb\"))\n",
    "pickle.dump(R_Rep4, open(\"data/R_Rep4.pickle\",\"wb\"))\n",
    "\n",
    "pickle.dump(R_Rep1_dict, open(\"data/R_Rep1_dict.pickle\",\"wb\"))\n",
    "pickle.dump(R_Rep2_dict, open(\"data/R_Rep2_dict.pickle\",\"wb\"))\n",
    "pickle.dump(R_Rep3_dict, open(\"data/R_Rep3_dict.pickle\",\"wb\"))\n",
    "pickle.dump(R_Rep4_dict, open(\"data/R_Rep4_dict.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(PBT_Rep1n, open(\"data/PBT_Rep1n.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep2n, open(\"data/PBT_Rep2n.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep3n, open(\"data/PBT_Rep3n.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep4n, open(\"data/PBT_Rep4n.pickle\",\"wb\"))\n",
    "\n",
    "pickle.dump(PBT_Rep1_dictn, open(\"data/PBT_Rep1_dictn.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep2_dictn, open(\"data/PBT_Rep2_dictn.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep3_dictn, open(\"data/PBT_Rep3_dictn.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep4_dictn, open(\"data/PBT_Rep4_dictn.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PBT_Rep1_dict.keys())\n",
    "print(PBT_Rep2_dict.keys())\n",
    "print(PBT_Rep3_dict.keys())\n",
    "print(PBT_Rep4_dict.keys())\n",
    "print(CMR_Rep1_dict.keys())\n",
    "print(CMR_Rep2_dict.keys())\n",
    "print(CMR_Rep3_dict.keys())\n",
    "print(CMR_Rep4_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(PBT_Rep1, open(\"data/PBT_Rep1.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep1, open(\"data/CMR_Rep1.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep2, open(\"data/PBT_Rep2.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep2, open(\"data/CMR_Rep2.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep3, open(\"data/PBT_Rep3.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep3, open(\"data/CMR_Rep3.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep4, open(\"data/PBT_Rep4.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep4, open(\"data/CMR_Rep4.pickle\",\"wb\"))\n",
    "\n",
    "pickle.dump(PBT_Rep1_dict, open(\"data/PBT_Rep1_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep1_dict, open(\"data/CMR_Rep1_dict.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep2_dict, open(\"data/PBT_Rep2_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep2_dict, open(\"data/CMR_Rep2_dict.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep3_dict, open(\"data/PBT_Rep3_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep3_dict, open(\"data/CMR_Rep3_dict.pickle\",\"wb\"))\n",
    "pickle.dump(PBT_Rep4_dict, open(\"data/PBT_Rep4_dict.pickle\",\"wb\"))\n",
    "pickle.dump(CMR_Rep4_dict, open(\"data/CMR_Rep4_dict.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in false_idx:\n",
    "#     if chems_maccs.iloc[i]['PBT/vPvB'] == 0:\n",
    "#         print(chems_maccs.iloc[i]['SMILES'])\n",
    "# # print(PBT_Rep1[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_idx = [70, 76, 125, 126, 128, 173, 203, 206, 209, 214, 244, 280, 310, 313, 317]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chems_maccs.iloc[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(chems_ext['CMR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmr_list = [214, 262, 342, 357, 87, 196, 468, 469, 806, 114, 470, 247, 256, 280, 352, 356, 482, 784, 25, 198, 303, 323, 360, 752, 78, 131, 138, 178, 249, 345, 164, 272, 348, 350, 825, 80, 88, 161, 181, 235, 298, 312, 490, 512, 783, 849, 192, 234, 760, 817, 836, 0, 238, 240, 291, 337, 885]\n",
    "# for s in list(np.array(chems_ext['SMILES'].tolist())[cmr_list]):\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for s in list(np.array(chems_maccs['SMILES'].tolist())[[244, 76, 317, 125, 126, 209, 173, 203, 70, 128, 481, 214, 310, 206, 313, 676, 280]]):\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gr_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[19, 81, 23, 92, 22, 921, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcule_graph.nodes)\n",
    "print(gr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = []\n",
    "for node in range(17):\n",
    "    if node < 8:\n",
    "        color_map.append('r')\n",
    "    else: \n",
    "        color_map.append('g')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "# gr=29\n",
    "# gr = 6\n",
    "\n",
    "gr = 27\n",
    "mcule_graph =nx.from_numpy_matrix(CMR_Rep1[gr]['bond_type'].numpy())\n",
    "pos = nx.spring_layout(mcule_graph)\n",
    "atoms1 = CMR_Rep1[gr]['atom_type'].nonzero()[1]\n",
    "gr_dict = {}\n",
    "for n, idx in enumerate(mcule_graph.nodes()):\n",
    "    gr_dict[n] = atoms1[idx]\n",
    "nx.draw_networkx_labels(mcule_graph, pos, labels=gr_dict)\n",
    "# nx.draw_networkx_edges(mcule_graph, pos)\n",
    "labels = nx.get_edge_attributes(mcule_graph,'weight')\n",
    "nx.draw_networkx_edge_labels(mcule_graph,pos,edge_labels=labels)\n",
    "nx.draw(mcule_graph, pos, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "mcule_graph = nx.from_numpy_matrix(CMR_Rep2[gr]['bond_type'].numpy())\n",
    "pos = nx.spring_layout(mcule_graph)\n",
    "atoms1 = CMR_Rep2[gr]['atom_type'].nonzero()[1]\n",
    "gr_dict = {}\n",
    "for n, idx in enumerate(mcule_graph.nodes()):\n",
    "    gr_dict[n] = atoms1[idx]\n",
    "nx.draw_networkx_labels(mcule_graph, pos,labels=gr_dict)\n",
    "labels = nx.get_edge_attributes(mcule_graph,'weight')\n",
    "nx.draw_networkx_edge_labels(mcule_graph,pos,edge_labels=labels)\n",
    "# nx.draw_networkx_nodes(mcule_graph, pos, node_list=[0,1,2,3,4], node_color=\"r\")\n",
    "# nx.draw_networkx_edges(mcule_graph,pos)\n",
    "nx.draw(mcule_graph, pos, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "mcule_graph = nx.from_numpy_matrix(PBT_Rep3n[gr]['bond_type'].numpy())\n",
    "pos = nx.spring_layout(mcule_graph)\n",
    "atoms1 = PBT_Rep3n[gr]['atom_type'].nonzero()[1]\n",
    "gr_dict = {}\n",
    "for n, idx in enumerate(mcule_graph.nodes()):\n",
    "    gr_dict[n] = atoms1[idx]\n",
    "nx.draw_networkx_labels(mcule_graph, pos, labels=gr_dict)\n",
    "labels = nx.get_edge_attributes(mcule_graph,'weight')\n",
    "nx.draw_networkx_edge_labels(mcule_graph,pos,edge_labels=labels)\n",
    "nx.draw(mcule_graph, pos, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PBT_Rep1[gr]['atom_type'].shape)\n",
    "print(PBT_Rep4[gr]['atom_type'].shape)\n",
    "print(sum(sum(PBT_Rep4[gr]['atom_type'])))\n",
    "print(CMR_Rep1[gr]['atom_type'].shape)\n",
    "print(CMR_Rep4[gr]['atom_type'].shape)\n",
    "print(sum(sum(CMR_Rep4[gr]['atom_type'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
