{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import argparse \n",
    "import itertools\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_config(configuration, first, last):\n",
    "    out = \"\"\n",
    "    for i in range(first, last + 1):\n",
    "        out = out + str(configuration[i]) + \" \"\n",
    "        \n",
    "    return out\n",
    "\n",
    "def get_num_running_jobs():\n",
    "    cmd = \"bjobs -q bio-gpu\"\n",
    "    returned_value = subprocess.run(cmd, capture_output=True, shell=True) \n",
    "    output = returned_value.stdout.decode()\n",
    "    \n",
    "    number_of_jobs = 0\n",
    "    if len(output) > 0: \n",
    "    \tnumber_of_jobs = len(output.split(\"\\n\")) - 2\n",
    "    \n",
    "    return number_of_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "output_path = './configs/test/' \n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "### GPU settings\n",
    "use = [True]\n",
    "id_gpu = [0]\n",
    "    \n",
    "### Test settings \n",
    "model = [\"GIN\"]\n",
    "dataset = [\"TOX\"]\n",
    "out_dir = [\"out/TOX_graph_classification/\"]\n",
    "\n",
    "### Parameter settings \n",
    "seed = [79]\n",
    "epochs = [1000]\n",
    "batch_size = [5]\n",
    "init_lr = [1e-5]\n",
    "lr_reduce_factor = [0.5]\n",
    "lr_schedule_patience = [25]\n",
    "min_lr = [1e-8]\n",
    "weight_decay = [0.0]\n",
    "print_epoch_interval = [5]\n",
    "max_time = [48]\n",
    "\n",
    "### net parameters settings\n",
    "L = [6]\n",
    "hidden_dim = [20]\n",
    "residual = [True]\n",
    "readout = [\"sum\"]\n",
    "n_mlp_GIN = [2]\n",
    "learn_eps_GIN = [True]\n",
    "neighbor_aggr_GIN = [\"sum\"]\n",
    "in_feat_dropout = [0]\n",
    "dropout = [0]\n",
    "graph_norm = [True]\n",
    "batch_norm = [True]\n",
    "\n",
    "\n",
    "gpu_combis = list(itertools.product(use, id_gpu))\n",
    "\n",
    "\n",
    "param_combis = list(itertools.product(seed,epochs,batch_size,init_lr,\n",
    "                                      lr_reduce_factor,lr_schedule_patience,\n",
    "                                      min_lr, weight_decay, print_epoch_interval, max_time))\n",
    "                    \n",
    "net_combis = list(itertools.product(L, hidden_dim, residual, readout, n_mlp_GIN, learn_eps_GIN,\n",
    "                                    neighbor_aggr_GIN, in_feat_dropout, dropout, graph_norm, batch_norm))\n",
    "\n",
    "combis = list(itertools.product(gpu_combis, model, dataset, out_dir, param_combis, net_combis))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"gpu\", \"model\", \"dataset\", \"out_dir\", \"params\", \"net_params\"]\n",
    "\n",
    "parameters = [\"seed\",\"epochs\",\"batch_size\",\"init_lr\",\"lr_reduce_factor\",\n",
    "              \"lr_schedule_patience\",\"min_lr\", \"weight_decay\", \"print_epoch_interval\", \"max_time\"]\n",
    "\n",
    "net = [\"L\", \"hidden_dim\", \"residual\", \"readout\", \"n_mlp_GIN\", \"learn_eps_GIN\", \"neighbor_aggr_GIN\",\n",
    "       \"in_feat_dropout\", \"dropout\", \"graph_norm\", \"batch_norm\"]\n",
    "\n",
    "gpu = [\"use\", \"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(comb_list, name_list):\n",
    "    dct = {}\n",
    "    for i in range(len(comb_list)):\n",
    "        dct[name_list[i]] = comb_list[i]\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(combis)):\n",
    "    combis[i] = create_dict(combis[i], headers)\n",
    "    combis[i][\"gpu\"] = create_dict(combis[i][\"gpu\"], gpu)\n",
    "    combis[i][\"params\"] = create_dict(combis[i][\"params\"], parameters)\n",
    "    combis[i][\"net_params\"] = create_dict(combis[i][\"net_params\"], net)\n",
    "    save_name = 'TOX' + combis[i]['model'] + str(i) +'.json'\n",
    "    with open(output_path + save_name, 'w') as fp:\n",
    "        json.dump(combis[i], fp, sort_keys=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(combis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bsub -q bio-tst -o bio_grid/TOXGIN0CMR_Rep1.txt -e bio_grid/TOXGIN0CMR_Rep1.txt python main_TUs_graph_classification.py --dataset CMR_Rep1 --config ./configs/test/TOXGIN12.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-60285460ff5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For loop creating jobs\n",
    "dataset = \"CMR_Rep\"\n",
    "# python $code --dataset $dataset --config 'configs/test/TOXGIN0.json'\n",
    "\n",
    "for i, configuration in enumerate(combis):\n",
    "    for j in [1,4]:\n",
    "        command = \"bsub -q bio-tst \"\n",
    "        pyth = \" python main_TUs_graph_classification.py --dataset \"\n",
    "        conf = \" --config \"\n",
    "        save_name = 'TOX' + configuration['model'] + str(i+12) +'.json'\n",
    "        out_name = 'TOX' + configuration['model'] + str(i) + dataset + str(j) + \".txt\"\n",
    "        out = \"-o bio_grid/\" + out_name\n",
    "        error = \" -e bio_grid/\" + out_name\n",
    "        job =  command + out + error + pyth + dataset + str(j) + conf + output_path + save_name\n",
    "\n",
    "        \n",
    "        # Wait until the job can be added to the queue\n",
    "#         while get_num_running_jobs() >= max_running_jobs:\n",
    "#             time.sleep(60)\n",
    "        \n",
    "        print(job)\n",
    "        os.system(job)\n",
    "        time.sleep(10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
